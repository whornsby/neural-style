{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Env/Program Setup"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorflow_version 1.x"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0akLeZBjEjDK",
        "outputId": "9e4a26fd-4f27-4829-991d-ef309aa26e05"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://github.com/whornsby/neural-style.git\n",
        "!mv neural-style/* .\n",
        "!rm -rf neural-style/"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "junvDfqyEsla",
        "outputId": "a968fe3b-523c-4ced-d862-57aba650acfc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install -r requirements.txt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dLREq5NGfvU",
        "outputId": "96fa85a9-4e21-4905-ca7d-205faa61cfcc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!curl 'https://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat' --output imagenet-vgg-verydeep-19.mat"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbw9Jgz-GfPU",
        "outputId": "abf15433-2818-430f-ce7b-b4c5effcc3e4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils and Project Code"
      ],
      "metadata": {
        "id": "ZZqohhNA9e5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from util import *\n",
        "from transfer import *"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Utils"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "\n",
        "def process_upload(img_data, content=False, style=False):\n",
        "  filename = list(img_data)[0]\n",
        "  temp_fn = filename.strip().replace(\" \", \"_\")\n",
        "\n",
        "  if filename != temp_fn:\n",
        "    os.rename(filename, temp_fn)\n",
        "    filename = temp_fn\n",
        "  \n",
        "  if content and style:\n",
        "    raise AttributeError(\"Image must be either content or style, not both\")\n",
        "  if content:\n",
        "    CONTENT_IMAGE_FN = filename\n",
        "    print(\"Content image filename:\", filename)\n",
        "    imgfig(filename, \"Content image\")\n",
        "  elif style:\n",
        "    STYLE_IMAGE_FN = filename\n",
        "    print(\"Style image filename:\", filename)\n",
        "    imgfig(filename, \"Style image\")\n",
        "  else:\n",
        "    print(\"Image saved with filename:\", filename)\n",
        "    imgshow(filename)"
      ],
      "outputs": [],
      "metadata": {
        "id": "rW1obdfw6dSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jobs"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "transfer_jobs = []\n",
        "outputs = []\n",
        "\n",
        "\n",
        "def run_jobs():\n",
        "  for job in transfer_jobs:\n",
        "    output_name = job.Output_name()\n",
        "    print(\"Generating \"+output_name+\"...\")\n",
        "    job.Execute()\n",
        "    outputs.append(output_name)\n",
        "    imgfig(output, \"Style Transferred Image - \" + output, 20)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drive"
      ],
      "metadata": {
        "id": "QBeHC6D3kYrJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ROOT_DIR_GDID = '13kelXjrToB3IpbHNj0WmRtP0yRNHcNUg'\n",
        "CONTENT_DIR_GDID = '11_SKmzv0UqQhxb-rgcLYVsF5sdfUlu6A'\n",
        "STYLE_DIR_GDID = '1ExIrZyGT2u4brgBIqVzQQk6-j63XP1xu'\n",
        "OUTPUT_DIR_GDID = '190RRdQlpmipXHztkyK1tF_6WTeA5Ulmo'\n",
        "\n",
        "'''Recursively search through Drive to find the file with a given name''' \n",
        "def get_file_from_name(name, start_id='root'):\n",
        "  parents = [start_id]\n",
        "  while parents:\n",
        "    pid = parents.pop()\n",
        "    listed = drive.ListFile({'q': f\"'{pid}' in parents\"}).GetList()\n",
        "    for file in listed:\n",
        "      if file['title'] == name:\n",
        "        pass \n",
        "      # return file\n",
        "      elif file['mimeType'] == 'application/vnd.google-apps.folder':\n",
        "          parents.append(file['id'])\n",
        "\n",
        "def get_file_by_id(id,name):\n",
        "  file = drive.CreateFile({'id': id})\n",
        "  file.GetContentFile('tmp/' + name)\n",
        "\n",
        "def upload_image(im_file, parent_folder, title=None):\n",
        "  if title is None:\n",
        "    title = im_file.split('/')[-1]\n",
        "\n",
        "  upload_file = drive.CreateFile({'title': title, 'parents': [{'id': parent_folder}]})\n",
        "  upload_file.SetContentFile(im_file)\n",
        "  upload_file.Upload()\n",
        "\n",
        "\n",
        "def download_image(filename, parent_id):\n",
        "  file_list = drive.ListFile({'q': f'{parent_id} in parents and trashed=false'})\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "wYvVda5hljO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual Upload"
      ],
      "metadata": {
        "id": "14Xa6dp0GKvI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Image Overrides\n",
        "manual_content_image = \"\" #@param {type:\"string\"}\n",
        "enable_content_override = True #@param {type:\"boolean\"}\n",
        "manual_style_image = \"\" #@param {type:\"string\"}\n",
        "enable_style_override = True #@param {type:\"boolean\"}\n",
        "\n",
        "if enable_content_override: CONTENT_IMAGE_FN = manual_content_image\n",
        "if enable_style_override: STYLE_IMAGE_FN = manual_style_image\n",
        "\n",
        "imgshow_h(CONTENT_IMAGE_FN, STYLE_IMAGE_FN)"
      ],
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "g3_mBPyESrHm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import files\n",
        "\n",
        "content_img = files.upload()\n",
        "process_upload(content_img, content=True)\n",
        "# CONTENT_IMAGE_FN = list(content_img)[0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "_VRlyZDDGFPS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "style_img = files.upload()\n",
        "process_upload(style_img, style=True)\n",
        "# STYLE_IMAGE_FN = list(style_img)[0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "o-6OGJVH-ytl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Style Transfer"
      ],
      "metadata": {
        "id": "a0RLzrNtHcES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title  { vertical-output: true }\n",
        "#@markdown #Command Parameters \n",
        "content_image = \"examples/1-content.jpg\" #@param {type:\"string\"}\n",
        "style_image = \"examples/1-style.jpg\" #@param {type:\"string\"}\n",
        "output_name = \"example1\" #@param {type:\"string\"}\n",
        "output_width = 1000 #@param {type:\"slider\", min:500, max:1920, step:10}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Processing\n",
        "\n",
        "iterations = 1000 #@param {type:\"slider\", min:500, max:2000, step:100}\n",
        "\n",
        "# Either 'max' or 'avg' - Default: 'max'\n",
        "# Original VGG topology uses max pooling, but paper suggests replacing it with avg.\n",
        "# The outputs are perceptually different, max in general tends to have finer detail style transfer, but could have troubles at lower-freqency detail level\n",
        "pooling = \"max\" #@param [\"max\", \"avg\"]\n",
        "preserve_colors = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown #### Logging\n",
        "# keep_progress_logs = False #@param {type:\"boolean\"}\n",
        "# print_iterations =   0 #@param {type:\"integer\"}\n",
        "# checkpoint_iterations = 200 #@param {type:\"integer\"}\n",
        "# checkpoint_output = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#TODO: checkpoint_output and checkpoint_iterations\n",
        "#TODO: style blending\n",
        "\n",
        "#@markdown ## Tuning\n",
        "#@markdown ### __Learning__\n",
        "#@markdown Weights are used in the cost function to balance the similarites of the content image and style image(s) to the generated image.\n",
        "#@markdown Learning rate is how quickly adjustments are made to lower the cost function.\n",
        "\n",
        "# content_weight_scale = 1 #@param {type:\"slider\", min:0.1, max:5, step:0.1}\n",
        "# style_weight_scale = 1 #@param {type:\"slider\", min:0.1, max:5, step:0.1}\n",
        "# learning_rate = 1 #@param {type:\"slider\", min:0.1, max:2, step:0.1}\n",
        "\n",
        "\n",
        "# #@markdown ### __Style Abstractness__\n",
        "# #@markdown _Float greater than 0.0 - Default: 1.0 (STYLE_LAYER_WEIGHT_EXP)_\n",
        "# #@markdown * Lower values mean __finer details__ of the style will be transfered (also preserves more details of the content image)\n",
        "# #@markdown * Higher values favor the __coarser/larger features__ of the style (can make output look more artsy since the details of the content image can not be represented by the larger stylistic features)\n",
        "# style_abstractness = 0.5 #@param {type:\"slider\", min:0.0, max:5.0, step:0.1}\n",
        "# style_abstractness_enabled = False #@param {type:\"boolean\"}\n",
        "\n",
        "# #@markdown ### Content Abstractness\n",
        "# #@markdown _Float between 0.0 and 1.0 - Default: 1.0 (CONTENT_WEIGHT_BLEND)_\n",
        "\n",
        "# #@markdown Conceptually similar to the above, but pertains the the detail/abstracness of the content image\n",
        "# #@markdown * Lower values make the output __MORE abstract__ (reverse of above)\n",
        "# content_abstractness = 1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1} \n",
        "# content_abstractness_enabled = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "# CONTENT_IMAGE_FN = content_image\n",
        "# STYLE_IMAGE_FN = style_image\n",
        "# # Script Variables\n",
        "# OUTPUT_WIDTH = output_width # min(output_width, Image.open(CONTENT_IMAGE_FN).size[0])\n",
        "# POOLING = pooling if pooling in ['max', 'avg'] else 'max'\n",
        "\n",
        "# CONTENT_WEIGHT = 5e0 * content_weight_scale  # pulled from neural-style defaults\n",
        "# STYLE_WEIGHT = 5e2 * style_weight_scale  # pulled from neural-style defaults\n",
        "# LEARNING_RATE = learning_rate\n",
        "\n",
        "# STYLE_LAYER_WEIGHT_EXP = style_abstractness if style_abstractness_enabled and 0 < style_abstractness else 1.0\n",
        "# CONTENT_WEIGHT_BLEND = content_abstractness if content_abstractness_enabled and 0 < content_abstractness < 1 else 1.0\n",
        "\n",
        "IS_TEST = True #@param {type:\"boolean\"}\n",
        "if IS_TEST:\n",
        "  output_width = 360\n",
        "  iterations = 50\n",
        "  output_name = \"TEST_\" + output_name\n",
        "  \n",
        "job = TransferJob(content_image, style_image, output_name, output_width)\n",
        "\n",
        "job.iterations(iterations)\n",
        "if preserve_colors:\n",
        "  job.preserve_colors()\n",
        "job.pooling(pooling)\n",
        "job.overwrite()\n",
        "\n",
        "# if keep_progress_logs: \n",
        "#   flags.append(\"--progress-write\")\n",
        "# if print_iterations > 0:\n",
        "#   flags.append(f\"--print-iterations {print_iterations}\")\n",
        "# if checkpoint_output:\n",
        "#   flags.append(f\"--checkpoint-output {output_filename}_%05d.jpg\")\n",
        "#   flags.append(f\"--checkpoint-iterations {checkpoint_iterations}\")\n",
        "\n",
        "# if content_weight_scale != 1:\n",
        "#   flags.append(f\"--content-weight {CONTENT_WEIGHT}\")\n",
        "#   param_string += f\"_cWgt{content_weight_scale}\"\n",
        "# if  style_weight_scale != 1:\n",
        "#   flags.append(f\"--style-weight {STYLE_WEIGHT}\")\n",
        "#   param_string += f\"_sWgt{style_weight_scale}\"\n",
        "# if learning_rate != 1:\n",
        "#   flags.append(f\"--learning-rate {LEARNING_RATE}\")\n",
        "#   param_string += f\"_lr{learning_rate}\"\n",
        "\n",
        "# if style_abstractness_enabled and style_abstractness != 1: \n",
        "#   flags.append(f\"--style-layer-weight-exp {STYLE_LAYER_WEIGHT_EXP}\")\n",
        "#   param_string += f\"_sAb{STYLE_LAYER_WEIGHT_EXP}\"\n",
        "# if content_abstractness_enabled and content_abstractness != 1: \n",
        "#   flags.append(f\"--content-weight-blend {CONTENT_WEIGHT_BLEND}\")\n",
        "#   param_string += f\"_cAb{CONTENT_WEIGHT_BLEND}\"\n",
        "\n",
        "TRANSFER_JOBS_LIST = \"RESET\" #@param [\"RESET\", \"APPEND\"]\n",
        "\n",
        "if TRANSFER_JOBS_LIST is \"RESET\":\n",
        "  transfer_jobs = [job]\n",
        "  print(output_name,\"-\",job.Output_name())\n",
        "elif TRANSFER_JOBS_LIST is \"APPEND\":\n",
        "  transfer_jobs.append(job)\n",
        "  print(output_name,\"-\",job.Output_name())\n",
        "\n",
        "print(\"\\nJobs to run:\")\n",
        "for j in transfer_jobs:\n",
        "  print(\"  \",j.Output_name())\n"
      ],
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fl8SCn8sm1w",
        "outputId": "b0cdc737-429a-498f-9b37-46123da2dd36"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "run_jobs()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for out in outputs:\n",
        "  imgfig(out, \"Style Transferred Image - \" + out, 20)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "kmn537DExvK-",
        "outputId": "f7d8d874-52c1-4221-d1b8-3dba4d368654"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Pwyg7-zSwKxY",
        "ZZqohhNA9e5Q"
      ],
      "name": "StyleTransfer.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}