{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwyg7-zSwKxY"
      },
      "outputs": [],
      "source": [
        "# Env/Program Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0akLeZBjEjDK",
        "outputId": "9e4a26fd-4f27-4829-991d-ef309aa26e05"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "junvDfqyEsla",
        "outputId": "a968fe3b-523c-4ced-d862-57aba650acfc"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/whornsby/neural-style.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dLREq5NGfvU",
        "outputId": "96fa85a9-4e21-4905-ca7d-205faa61cfcc"
      },
      "outputs": [],
      "source": [
        "!pip install -r neural-style/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbw9Jgz-GfPU",
        "outputId": "abf15433-2818-430f-ce7b-b4c5effcc3e4"
      },
      "outputs": [],
      "source": [
        "!curl 'https://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat' --output imagenet-vgg-verydeep-19.mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZqohhNA9e5Q"
      },
      "source": [
        "# Utils and Project Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgpUpZIjiKpB"
      },
      "outputs": [],
      "source": [
        "'''Display a single image'''\n",
        "def imgfig(img_file, title, size=10):\n",
        "  fig = plt.figure(figsize=(size, size))\n",
        "  img = plt.imread(img_file)\n",
        "  plt.axis('off')\n",
        "  plt.title(title)\n",
        "  plt.imshow(img)\n",
        "\n",
        "\n",
        "'''Display a list of images vertically'''\n",
        "def imgshow(img_file, *img_files): \n",
        "  n = len(img_files) + 1\n",
        "  fig, ax = plt.subplots(n,1,figsize=(8, 8*n))\n",
        "\n",
        "  if n == 1:\n",
        "    ax.axis('off')\n",
        "    ax.set_title(img_file)\n",
        "    im = plt.imread(img_file)\n",
        "    ax.imshow(im)\n",
        "  else:\n",
        "    imgs = (img_file,) + img_files\n",
        "    for i, imfile in enumerate(imgs):\n",
        "      ax[i].axis('off')\n",
        "      ax[i].set_title(imfile)\n",
        "      im = plt.imread(imfile)\n",
        "      ax[i].imshow(im)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "'''Display a list of images horizontally'''\n",
        "def imgshow_h(img_file, *img_files): \n",
        "  n = len(img_files) + 1\n",
        "  fig, ax = plt.subplots(1,n,figsize=(8, 8*n))\n",
        "\n",
        "  if n == 1:\n",
        "    ax.axis('off')\n",
        "    ax.set_title(img_file)\n",
        "    im = plt.imread(img_file)\n",
        "    ax.imshow(im)\n",
        "  else:\n",
        "    imgs = (img_file,) + img_files\n",
        "    for i, imfile in enumerate(imgs):\n",
        "      ax[i].axis('off')\n",
        "      ax[i].set_title(imfile)\n",
        "      im = plt.imread(imfile)\n",
        "      ax[i].imshow(im)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW1obdfw6dSz"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def process_upload(img_data, content=False, style=False):\n",
        "  filename = list(img_data)[0]\n",
        "  temp_fn = filename.strip().replace(\" \", \"_\")\n",
        "\n",
        "  if filename != temp_fn:\n",
        "    os.rename(filename, temp_fn)\n",
        "    filename = temp_fn\n",
        "  \n",
        "  if content and style:\n",
        "    raise AttributeError(\"Image must be either content or style, not both\")\n",
        "  if content:\n",
        "    CONTENT_IMAGE_FN = filename\n",
        "    print(\"Content image filename:\", filename)\n",
        "    imgfig(filename, \"Content image\")\n",
        "  elif style:\n",
        "    STYLE_IMAGE_FN = filename\n",
        "    print(\"Style image filename:\", filename)\n",
        "    imgfig(filename, \"Style image\")\n",
        "  else:\n",
        "    print(\"Image saved with filename:\", filename)\n",
        "    imgshow(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Xa6dp0GKvI"
      },
      "source": [
        "# Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEmKAySikjur"
      },
      "source": [
        "## Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VRlyZDDGFPS"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "content_img = files.upload()\n",
        "process_upload(content_img, content=True)\n",
        "CONTENT_IMAGE_FN = list(content_img)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-6OGJVH-ytl"
      },
      "outputs": [],
      "source": [
        "style_img = files.upload()\n",
        "process_upload(style_img, style=True)\n",
        "STYLE_IMAGE_FN = list(style_img)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "g3_mBPyESrHm"
      },
      "outputs": [],
      "source": [
        "#@title Image Overrides\n",
        "manual_content_image = \"marsh8.jpg\" #@param {type:\"string\"}\n",
        "enable_content_override = True #@param {type:\"boolean\"}\n",
        "manual_style_image = \"surreal_boat.jpeg\" #@param {type:\"string\"}\n",
        "enable_style_override = True #@param {type:\"boolean\"}\n",
        "\n",
        "if enable_content_override: CONTENT_IMAGE_FN = manual_content_image\n",
        "if enable_style_override: STYLE_IMAGE_FN = manual_style_image\n",
        "\n",
        "imgshow_h(CONTENT_IMAGE_FN, STYLE_IMAGE_FN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBeHC6D3kYrJ"
      },
      "source": [
        "## Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTWBsvoHm-O4"
      },
      "outputs": [],
      "source": [
        "MNT_PATH = '/content/drive'\n",
        "PHOTO_PATH = MNT_PATH + '/MyDrive/StyleTransferPhotos'\n",
        "CONTENT_PATH = PHOTO_PATH + '/content/'\n",
        "STYLE_PATH = PHOTO_PATH + '/style/'\n",
        "OUTPUT_PATH = PHOTO_PATH + '/output/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TdC0YpwmI-w",
        "outputId": "dc5ff459-a563-475f-f58e-cd5dfbac9d5a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(MNT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maqlS8BOm5BT"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYvVda5hljO6"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR_GDID = '13kelXjrToB3IpbHNj0WmRtP0yRNHcNUg'\n",
        "CONTENT_DIR_GDID = '11_SKmzv0UqQhxb-rgcLYVsF5sdfUlu6A'\n",
        "STYLE_DIR_GDID = '1ExIrZyGT2u4brgBIqVzQQk6-j63XP1xu'\n",
        "OUTPUT_DIR_GDID = '190RRdQlpmipXHztkyK1tF_6WTeA5Ulmo'\n",
        "\n",
        "def get_file_from_name(name, start_id='root'):\n",
        "  parents = [start_id]\n",
        "  while parents:\n",
        "    pid = parents.pop()\n",
        "    listed = drive.ListFile({'q': f\"'{pid}' in parents\"}).GetList()\n",
        "    for f in listed:\n",
        "      if file['title'] == name:\n",
        "        return file\n",
        "      else: \n",
        "        if file['mimeType'] == 'application/vnd.google-apps.folder':\n",
        "          parents.append(file['id'])\n",
        "\n",
        "\n",
        "def upload_image(im_file, parent_folder, title=None):\n",
        "  if title is None:\n",
        "    title = im_file.split('/')[-1]\n",
        "\n",
        "  upload_file = drive.CreateFile({'title': title})\n",
        "  upload_file.SetContentFile(im_file)\n",
        "  upload_file.Upload()\n",
        "\n",
        "\n",
        "def download_image(filename, parent_id):\n",
        "  file_list = drive.ListFile({'q': f'{parent_id} in parents and trashed=false'})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0RLzrNtHcES"
      },
      "source": [
        "# Style Transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block (<ipython-input-2-0ed9a513ad6e>, line 40)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-0ed9a513ad6e>\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    def Run(self):\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ],
      "source": [
        "from transfer import TransferJob\n",
        "\n",
        "transfer_jobs = []\n",
        "outputs = []\n",
        "\n",
        "def run_jobs():\n",
        "  for job in transfer_jobs:\n",
        "    output_name = job.Output_name()\n",
        "    cmd = job.Cmd()\n",
        "    print(\"Running Command:\")\n",
        "    print('\\n  --'.join(cmd.split('--')))\n",
        "    !{cmd}\n",
        "    outputs.append(output_name)\n",
        "    imgfig(output, \"Style Transferred Image - \" + output, 20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fl8SCn8sm1w",
        "outputId": "b0cdc737-429a-498f-9b37-46123da2dd36"
      },
      "outputs": [],
      "source": [
        "#@title  { run: \"auto\", vertical-output: true }\n",
        "#@markdown #Command Parameters \n",
        "content_image = \"/space/washington_space.jpg\" #@param {type:\"string\"}\n",
        "style_image = \"/space/bloom_nebula.jpeg\" #@param {type:\"string\"}\n",
        "output_dir = \"washington_space\" #@param {type:\"string\"}\n",
        "output_filename = \"wa_space_nebula\" #@param {type:\"string\"}\n",
        "output_width = 1000 #@param {type:\"slider\", min:500, max:1920, step:10}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Processing\n",
        "\n",
        "iterations = 1000 #@param {type:\"slider\", min:500, max:2000, step:100}\n",
        "\n",
        "# Either 'max' or 'avg' - Default: 'max'\n",
        "# Original VGG topology uses max pooling, but paper suggests replacing it with avg.\n",
        "# The outputs are perceptually different, max in general tends to have finer detail style transfer, but could have troubles at lower-freqency detail level\n",
        "pooling = \"max\" #@param [\"max\", \"avg\"]\n",
        "preserve_colors = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown #### Logging\n",
        "keep_progress_logs = False #@param {type:\"boolean\"}\n",
        "print_iterations =   0 #@param {type:\"integer\"}\n",
        "checkpoint_iterations = 200 #@param {type:\"integer\"}\n",
        "checkpoint_output = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#TODO: checkpoint_output and checkpoint_iterations\n",
        "#TODO: style blending\n",
        "\n",
        "#@markdown ## Tuning\n",
        "#@markdown ### __Learning__\n",
        "#@markdown Weights are used in the cost function to balance the similarites of the content image and style image(s) to the generated image.\n",
        "#@markdown Learning rate is how quickly adjustments are made to lower the cost function.\n",
        "\n",
        "content_weight_scale = 1 #@param {type:\"slider\", min:0.1, max:5, step:0.1}\n",
        "style_weight_scale = 1 #@param {type:\"slider\", min:0.1, max:5, step:0.1}\n",
        "learning_rate = 1 #@param {type:\"slider\", min:0.1, max:2, step:0.1}\n",
        "\n",
        "\n",
        "#@markdown ### __Style Abstractness__\n",
        "#@markdown _Float greater than 0.0 - Default: 1.0 (STYLE_LAYER_WEIGHT_EXP)_\n",
        "#@markdown * Lower values mean __finer details__ of the style will be transfered (also preserves more details of the content image)\n",
        "#@markdown * Higher values favor the __coarser/larger features__ of the style (can make output look more artsy since the details of the content image can not be represented by the larger stylistic features)\n",
        "style_abstractness = 0.5 #@param {type:\"slider\", min:0.0, max:5.0, step:0.1}\n",
        "style_abstractness_enabled = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Content Abstractness\n",
        "#@markdown _Float between 0.0 and 1.0 - Default: 1.0 (CONTENT_WEIGHT_BLEND)_\n",
        "\n",
        "#@markdown Conceptually similar to the above, but pertains the the detail/abstracness of the content image\n",
        "#@markdown * Lower values make the output __MORE abstract__ (reverse of above)\n",
        "content_abstractness = 1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1} \n",
        "content_abstractness_enabled = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "CONTENT_IMAGE_FN = CONTENT_PATH + content_image\n",
        "STYLE_IMAGE_FN = STYLE_PATH + style_image\n",
        "# Script Variables\n",
        "OUTPUT_WIDTH = output_width # min(output_width, Image.open(CONTENT_IMAGE_FN).size[0])\n",
        "POOLING = pooling if pooling in ['max', 'avg'] else 'max'\n",
        "\n",
        "CONTENT_WEIGHT = 5e0 * content_weight_scale  # pulled from neural-style defaults\n",
        "STYLE_WEIGHT = 5e2 * style_weight_scale  # pulled from neural-style defaults\n",
        "LEARNING_RATE = learning_rate\n",
        "\n",
        "STYLE_LAYER_WEIGHT_EXP = style_abstractness if style_abstractness_enabled and 0 < style_abstractness else 1.0\n",
        "CONTENT_WEIGHT_BLEND = content_abstractness if content_abstractness_enabled and 0 < content_abstractness < 1 else 1.0\n",
        "\n",
        "\n",
        "from transfer import TransferJob\n",
        "job = TransferJob(CONTENT_IMAGE_FN, STYLE_IMAGE_FN, output_filename)\n",
        "\n",
        "\n",
        "if iterations != 1000:\n",
        "  job.iterations(1000)\n",
        "if preserve_colors:\n",
        "  job.preserve_colors()\n",
        "job.pooling(POOLING)\n",
        "\n",
        "job.overwrite()\n",
        "\n",
        "transfer_jobs.append(job)\n",
        "\n",
        "\n",
        "# if keep_progress_logs: \n",
        "#   flags.append(\"--progress-write\")\n",
        "# if print_iterations > 0:\n",
        "#   flags.append(f\"--print-iterations {print_iterations}\")\n",
        "# if checkpoint_output:\n",
        "#   flags.append(f\"--checkpoint-output {output_filename}_%05d.jpg\")\n",
        "#   flags.append(f\"--checkpoint-iterations {checkpoint_iterations}\")\n",
        "\n",
        "# if content_weight_scale != 1:\n",
        "#   flags.append(f\"--content-weight {CONTENT_WEIGHT}\")\n",
        "#   param_string += f\"_cWgt{content_weight_scale}\"\n",
        "# if  style_weight_scale != 1:\n",
        "#   flags.append(f\"--style-weight {STYLE_WEIGHT}\")\n",
        "#   param_string += f\"_sWgt{style_weight_scale}\"\n",
        "# if learning_rate != 1:\n",
        "#   flags.append(f\"--learning-rate {LEARNING_RATE}\")\n",
        "#   param_string += f\"_lr{learning_rate}\"\n",
        "\n",
        "# if style_abstractness_enabled and style_abstractness != 1: \n",
        "#   flags.append(f\"--style-layer-weight-exp {STYLE_LAYER_WEIGHT_EXP}\")\n",
        "#   param_string += f\"_sAb{STYLE_LAYER_WEIGHT_EXP}\"\n",
        "# if content_abstractness_enabled and content_abstractness != 1: \n",
        "#   flags.append(f\"--content-weight-blend {CONTENT_WEIGHT_BLEND}\")\n",
        "#   param_string += f\"_cAb{CONTENT_WEIGHT_BLEND}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_jobs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "NJgrxZomUSQ9",
        "outputId": "507986e6-bfd3-436a-cf14-1dda6d72ff6e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(MNT_PATH)\n",
        "\n",
        "imgshow_h(CONTENT_IMAGE_FN, STYLE_IMAGE_FN)\n",
        " \n",
        "!CMD\n",
        "\n",
        "imgfig(OUTPUT_IMAGE_FN, \"Style Transferred Image - \" + OUTPUT_IMAGE_FN, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "kmn537DExvK-",
        "outputId": "f7d8d874-52c1-4221-d1b8-3dba4d368654"
      },
      "outputs": [],
      "source": [
        "# imgshow(CONTENT_IMAGE_FN, STYLE_IMAGE_FN, OUTPUT_IMAGE_FN)\n",
        "imgfig(OUTPUT_IMAGE_FN, \"Style Transferred Image - \" + OUTPUT_IMAGE_FN, 20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Pwyg7-zSwKxY",
        "ZZqohhNA9e5Q"
      ],
      "name": "StyleTransfer.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}